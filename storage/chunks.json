[
  {
    "id": "job_mistral_intern_summary_0",
    "doc_id": "job_mistral_intern_summary",
    "title": "job_mistral_intern_summary.md",
    "text": "# job_mistral_intern_summary.md\n**Role:** Software Engineer - Paris (Internship)  \n**Source:** https://jobs.lever.co/mistral/a6980b07-e55a-427c-a985-38ecd1e2eea6  \n**Captured:** 2026-01-22  \n**Note:** This is a *summary* for RAG. For the exact wording, see the official posting at the source URL.\n\n---\n\n## 1) Application requirements (from the posting, paraphrased)\n\n- To apply, candidates must provide a GitHub repository and complete a project.\n- Suggested project directions include:\n  - a Next.js chat app using Mistral’s public API,\n  - a Python project (e.g., using vLLM or similar),\n  - or a flexible topic that uses Python/FastAPI or Next.js/TypeScript and incorporates Mistral’s SDK.\n- They will pay particular attention to:\n  - a detailed README,\n  - and making the project easy to test.\n\n---\n\n## 2) Role summary (paraphrased)\n\n- You’d work with the engineering team and learn specifics of AI software.\n- You’d build both internal and external tooling.\n- Location: Paris (on-site).\n- Internship duration: 4–6 months; they prioritize candidates able to join full-time after a successful internship.\n\n---\n\n## 3) What you will do (paraphrased)\n\n- Build user-facing internal/external apps powered by Mistral models (examples: chatbot, search, document answering).\n- Instrument products with developer-facing tools (examples: dashboards, evaluation interfaces).\n\n---\n\n## 4) About you (paraphrased)\n\n- Strong full-stack skills (Python / TypeScript / JavaScript) **or** infrastructure skills (Kubernetes / CI).\n- Ability to create smooth, high-quality user experiences for both developers and end users.\n- Appetite for building AI solutions with chat APIs, embedding APIs, etc.\n- Ability to adapt quickly and evolve in a fast-changing environment.\n\n---\n\n## 5) Interview process (paraphrased)\n\n- Submit GitHub + project\n- Coding interview\n- System design interview\n- Interview with engineering team lead\n"
  },
  {
    "id": "mistral_about_0",
    "doc_id": "mistral_about",
    "title": "mistral_about.md",
    "text": "# mistral_about.md\n**Purpose:** A short, retrieval-friendly dossier on Mistral AI for the HireMeGPT RAG corpus.  \n**Last updated:** 2026-01-22\n\n---\n\n## 1) What Mistral is (high level)\n\nMistral AI is an AI company building large language models (LLMs) and products around them, including “Le Chat,” their assistant for work and life. Mistral emphasizes strong performance and a platform designed for enterprise needs (including deployment flexibility like cloud or on‑prem).  \n\n---\n\n## 2) What the internship cares about (product & engineering culture signals)\n\nFrom the internship posting:\n- They care about projects that are **easy to test** and come with a **detailed README**.\n- They suggest building a **Next.js chat application** using their public API, or a **Python project** (e.g., with FastAPI), and generally want you to incorporate their SDK.\n\n---\n\n## 3) Mistral platform signals (developer lens)\n\nFrom Mistral’s docs:\n- Mistral exposes **chat** and **embeddings** capabilities via API.\n- Their docs include a “RAG quickstart” that demonstrates:\n  - chunking text,\n  - embedding with the `mistral-embed` model,\n  - indexing in a vector store (FAISS),\n  - retrieving top‑K context, and\n  - generating an answer grounded in retrieved context.\n\n---\n\n## 4) Why this matters for the project\n\nFor the internship application project, the most relevant “Mistral-aligned” demonstration is:\n- A Next.js chat UI with streaming + good UX,\n- A Python/FastAPI backend,\n- A simple but real RAG system using Mistral embeddings (`mistral-embed`) + FAISS retrieval,\n- Basic developer tooling (an eval page, logs, and clear documentation).\n\n---\n\n## 5) References (URLs)\n- Internship posting on Lever (role description + requirements)\n- Mistral Docs: RAG Quickstart (embeddings + FAISS example)\n- Mistral Docs: Models list (model naming and availability)\n"
  },
  {
    "id": "thomas_outreach_excerpts_0",
    "doc_id": "thomas_outreach_excerpts",
    "title": "thomas_outreach_excerpts.md",
    "text": "# thomas_outreach_excerpts.md\n**Purpose:** Short, punchy “proof phrasing” the agent can reuse.  \n**Source:** Extracted/derived from Thomas’s outreach templates and cover letters. fileciteturn1file7L3-L8 fileciteturn1file3L18-L24 fileciteturn1file4L19-L24\n\n---\n\n## 1) Ultra-short taglines (pick one)\n- “High-agency builder who learns fast and ships.” fileciteturn1file9L61-L67  \n- “Coachable engineer who iterates quickly on feedback.” fileciteturn1file9L65-L67  \n- “Engineer who’s shipped AI in regulated workflows.” fileciteturn1file10L1-L3  \n\n---\n\n## 2) The 3-bullet ‘Why hire me’ template (tight)\nUse this structure for “Why hire you?” answers:\n\n1) **Fast builder:** I solo-designed, built, and deployed a compliant AI product used in clinics. fileciteturn1file7L19-L23  \n2) **Applied AI systems:** I built agentic RAG workflows with retrieval tools and optimized for auditability. fileciteturn1file2L16-L24  \n3) **Coachable + high-agency:** I’m curious, learn fast, and thrive in high-standards teams. fileciteturn1file7L44-L49 fileciteturn1file9L61-L67  \n\nThen: **one concrete metric** (e.g., “>90% CPT identification on 500+ notes”) and a **closing question**.\n\n---\n\n## 3) “What I’m excited about” phrasing\n- I’m excited about work at the intersection of powerful models and real product workflows: building interfaces and verification layers so people can trust what the model is doing. fileciteturn1file4L19-L21  \n- I like turning early prototypes into something reliable and repeatable. fileciteturn1file4L1-L4  \n\n---\n\n## 4) Friendly closing questions (to keep it interactive)\n- “Want the product angle or the systems angle?”\n- “Should I go deeper on the RAG design, or the UX decisions?”\n- “What would you prioritize first if I joined—features, evals, or reliability?”\n"
  },
  {
    "id": "thomas_profile_0",
    "doc_id": "thomas_profile",
    "title": "thomas_profile.md",
    "text": "# thomas_profile.md (v2)\n**Owner:** Thomas Fortoul  \n**Last updated:** 2026-01-22  \n**Use:** Ground truth for the “Thomas persona” in HireMeGPT.\n\n---\n\n## 1) 10-second summary\nHigh-agency technical founder with a B.Sc. in Computer Science. I’ve shipped a HIPAA-compliant AI medical coding web app end-to-end, built agentic/RAG-style workflows, and I like turning strong models into real products with clean UX and solid engineering. fileciteturn1file5L2-L12\n\n---\n\n## 2) The pitch (what I want you to remember)\nIf you hire me, you get:\n- **A fast builder** who can ship full-stack (Next.js/TS + Python + cloud) and keep the repo clean + testable. fileciteturn1file5L7-L12  \n- **An applied AI engineer** who’s actually built agentic workflows with retrieval tools and iterated for real-world constraints (speed + auditability). fileciteturn1file5L8-L12  \n- **A high-agency teammate** who learns fast, takes feedback seriously, and turns it into repeatable systems. fileciteturn1file5L2-L5 fileciteturn1file3L22-L24\n\n---\n\n## 3) Proof points (use these for “why hire you?”)\n### Oxkair (Co-Founder, CTO) — Healthcare AI\n- Built a **HIPAA-compliant AI medical coding web app** end-to-end in **under 1 month** (TypeScript, Postgres, Azure). fileciteturn1file5L7-L9  \n- Built an **agentic workflow with retrieval tools**, achieving **>90% CPT identification** on **500+ operative notes**. fileciteturn1file5L8-L10  \n- Added auth + role-based access control and deployed within private Azure VNets. fileciteturn1file5L10-L11  \n- Optimized for clinical use: **~30s processing time**, iterated based on user feedback. fileciteturn1file5L11-L12  \n\n### Communication / customer-facing strength\n- Closed **3 deals end-to-end** (~$25K ACV, 1–5 week cycles) and improved delivery timelines by **40%** (Solar Broker). fileciteturn1file5L13-L16  \n- Hosted ~20 interviews with CEOs/founders (Pioneer Series), strong in prep + structured conversations. fileciteturn1file5L27-L29  \n\n### ML / systems experience\n- Built multi-n"
  },
  {
    "id": "thomas_profile_1",
    "doc_id": "thomas_profile",
    "title": "thomas_profile.md",
    "text": "rn1file5L13-L16  \n- Hosted ~20 interviews with CEOs/founders (Pioneer Series), strong in prep + structured conversations. fileciteturn1file5L27-L29  \n\n### ML / systems experience\n- Built multi-node infra + real-time ingestion + ML pipelines + retraining + alerts (Cobalt Alternative Investment). fileciteturn1file5L22-L25  \n- Improved performance by **12%** with feature engineering + tuning; worked with **10,000+** time-series points. fileciteturn1file5L25-L26  \n\n---\n\n## 4) How I work (tone & behaviors)\n- I like steep learning curves and high standards. fileciteturn1file9L61-L67  \n- I’m **coachable**: I take feedback seriously, iterate quickly, and systematize what works. fileciteturn1file3L22-L24  \n- I’m product-minded: I care about clarity, auditability, and “does it actually work for the user?” fileciteturn1file4L1-L4 fileciteturn1file5L11-L12  \n\n---\n\n## 5) Motivation (why Mistral / why now)\n- I’m specifically interested in building **advanced AI systems that people can trust and actually use**—interfaces, workflows, and verification layers that make strong models feel reliable in practice. fileciteturn1file4L19-L21  \n- I want to learn with world-class talent and ship at a very high bar.  \n- I’m also personally invested in Europe’s AI future: I genuinely think **France should be a leading country in the AI race**, and I want to contribute by building excellent products.\n\n---\n\n## 6) Quick facts\n- B.Sc. Computer Science (McGill), minor in Biotechnology, GPA 3.82/4.00. fileciteturn1file14L20-L23  \n- Languages: French (native), English (fluent), Spanish (proficient). fileciteturn1file14L30-L31  \n- Tech: Python, TypeScript/JS, SQL/Postgres, Next.js, Azure, Docker, Git/GitHub. fileciteturn1file14L24-L31\n"
  }
]